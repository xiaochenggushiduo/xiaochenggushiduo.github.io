<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>深度学习 | 🤔</title>
    <meta name="description" content="用以致学">
    <link rel="icon" href="/logo2.png">
    
    <link rel="preload" href="/assets/css/0.styles.6297f5e0.css" as="style"><link rel="preload" href="/assets/js/app.b74a338b.js" as="script"><link rel="preload" href="/assets/js/6.1e25e40e.js" as="script"><link rel="prefetch" href="/assets/js/10.120375b3.js"><link rel="prefetch" href="/assets/js/11.b8821cbd.js"><link rel="prefetch" href="/assets/js/12.f76ea299.js"><link rel="prefetch" href="/assets/js/13.2c32402f.js"><link rel="prefetch" href="/assets/js/14.52e6be6c.js"><link rel="prefetch" href="/assets/js/15.b6af3c66.js"><link rel="prefetch" href="/assets/js/2.605ea5ed.js"><link rel="prefetch" href="/assets/js/3.ec6615b3.js"><link rel="prefetch" href="/assets/js/4.c9993dc3.js"><link rel="prefetch" href="/assets/js/5.6df627ac.js"><link rel="prefetch" href="/assets/js/7.822d9c04.js"><link rel="prefetch" href="/assets/js/8.ac3b254b.js"><link rel="prefetch" href="/assets/js/9.cae94da3.js">
    <link rel="stylesheet" href="/assets/css/0.styles.6297f5e0.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">🤔</span></a> <div class="links" style="max-width:nullpx;"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">主页</a></div><div class="nav-item"><a href="/post/" class="nav-link">上网导航</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title">文档</span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/machinelearn/" class="nav-link">机器学习</a></li><li class="dropdown-item"><!----> <a href="/deeplearn/" class="nav-link router-link-active">深度学习</a></li><li class="dropdown-item"><!----> <a href="/statistics/" class="nav-link">统计方法</a></li></ul></div></div><div class="nav-item"><a href="/fiction/" class="nav-link">小说</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">主页</a></div><div class="nav-item"><a href="/post/" class="nav-link">上网导航</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title">文档</span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/machinelearn/" class="nav-link">机器学习</a></li><li class="dropdown-item"><!----> <a href="/deeplearn/" class="nav-link router-link-active">深度学习</a></li><li class="dropdown-item"><!----> <a href="/statistics/" class="nav-link">统计方法</a></li></ul></div></div><div class="nav-item"><a href="/fiction/" class="nav-link">小说</a></div> <!----></nav>  <ul class="sidebar-links"><li><div class="sidebar-group first"><p class="sidebar-heading open"><span>深度学习</span> <!----></p> <ul class="sidebar-group-items"><li><a href="/deeplearn/deeplearn.html#logistic-回归" class="sidebar-link">logistic 回归</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/deeplearn/deeplearn.html#损失函数" class="sidebar-link">损失函数</a></li><li class="sidebar-sub-header"><a href="/deeplearn/deeplearn.html#学习率" class="sidebar-link">学习率</a></li></ul></li><li><a href="/deeplearn/deeplearn.html#浅层网络" class="sidebar-link">浅层网络</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/deeplearn/deeplearn.html#激活函数" class="sidebar-link">激活函数</a></li><li class="sidebar-sub-header"><a href="/deeplearn/deeplearn.html#如何初始化参数-w、b-的值？" class="sidebar-link">如何初始化参数 w、b 的值？</a></li></ul></li><li><a href="/deeplearn/deeplearn.html#深度神经网络" class="sidebar-link">深度神经网络</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/deeplearn/deeplearn.html#偏差与方差" class="sidebar-link">偏差与方差</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/deeplearn/deeplearn.html#正则化" class="sidebar-link">正则化</a></li></ul></li></ul></div></li></ul> </div> <div class="page"> <div class="content"><h1 id="深度学习">深度学习</h1> <p>标准的神经网络（NN）可用于训练房子特征和房价之间的函数，</p> <p>卷积神经网络（CNN）可用于训练图像和类别之间的函数，</p> <p>循环神经网络（RNN）可用于训练语音和文本之间的函数</p> <p>NN 使用的是<strong>权重矩阵</strong>（连接）和节点值相乘并陆续传播至下一层节点的方式；</p> <p>CNN 使用<strong>矩形卷积核</strong>在图像输入上依次进行卷积操作、滑动，得到下一层输入的方式；</p> <p>RNN <strong>记忆或遗忘先前时间步的信息</strong>以为当前计算过程提供长期记忆。</p> <p>深度学习研究的一大突破是新型激活函数的出现，<strong>用 ReLU 函数替换sigmoid 函数可以在反向传播中保持快速的梯度下降过程</strong>，sigmoid 函数在正无穷处和负无穷处会出现趋于零的导数，这正是梯度消失导致训练缓慢甚至失败的主要原因。要研究深度学习，需要学会「idea—代码—实验—idea」的良性循环。</p> <h2 id="logistic-回归">logistic 回归</h2> <p>将 logistic 回归看成将两组数据点分离的问题，如果仅有线性回归（激活函数为线性），则对于非线性边界的数据点（例如，一组数据点被另一组包围）是无法有效分离的，因此在这里需要用非线性激活函数替换线性激活函数。</p> <h3 id="损失函数">损失函数</h3> <p>这个分类其实就是一个优化问题，优化过程的目的是使预测值 y hat 和真实值 y 之间的差距最小，形式上可以通过寻找目标函数的最小值来实现。所以我们首先确定目标函数（损失函数、代价函数）的形式，然后用梯度下降逐步更新 w、b，当<strong>损失函数达到最小值或者足够小</strong>时，我们就能获得很好的预测结果。</p> <h3 id="学习率">学习率</h3> <p>使用梯度可以找到最快的下降路径，学习率的大小可以决定收敛的速度和最终结果。学习率较大时，初期收敛很快，不易停留在局部极小值，但后期难以收敛到稳定的值；学习率较小时，情况刚好相反。一般而言，我们希望训练初期学习率较大，后期学习率较小，之后会介绍变化学习率的训练方法。</p> <p>总结整个训练过程，从输入节点 x 开始，通过前向传播得到预测输出 y hat，用 y hat 和 y 得到损失函数值，开始执行反向传播，更新 w 和 b，重复迭代该过程，直到收敛。</p> <h2 id="浅层网络">浅层网络</h2> <h3 id="激活函数">激活函数</h3> <p>sigmoid：sigmoid 函数常用于二分分类问题，或者多分类问题的最后一层，主要是由于其归一化特性。sigmoid 函数在两侧会出现梯度趋于零的情况，会导致训练缓慢。</p> <p>tanh：相对于 sigmoid，tanh 函数的优点是梯度值更大，可以使训练速度变快。</p> <p>ReLU：可以理解为阈值激活（spiking model 的特例，类似生物神经的工作方式），该函数很常用，基本是默认选择的激活函数，优点是不会导致训练缓慢的问题，并且由于激活值为零的节点不会参与反向传播，该函数还有稀疏化网络的效果。</p> <p>Leaky ReLU：避免了零激活值的结果，使得反向传播过程始终执行，但在实践中很少用。</p> <p>没有使用非线性激活函数的话，无论多少层的神经网络都等价于单层神经网络（不包含输入层）。</p> <h3 id="如何初始化参数-w、b-的值？">如何初始化参数 w、b 的值？</h3> <p>随机初始化所有参数，但仅需少量的方差就行，因此使用 Rand（0.01）进行初始化，其中 0.01 也是超参数之一。</p> <h2 id="深度神经网络"><strong>深度神经网络</strong></h2> <p>CNN 的深度网络可以将底层的简单特征逐层组合成越来越复杂的特征，深度越大，其能分类的图像的复杂度和多样性就越大。RNN 的深度网络也是同样的道理，可以将语音分解为音素，再逐渐组合成字母、单词、句子，执行复杂的语音到文本任务。深度网络的特点是需要大量的训练数据和计算资源，其中涉及大量的矩阵运算，可以在 GPU 上并行执行，还包含了大量的超参数，例如学习率、迭代次数、隐藏层数、激活函数选择、学习率调整方案、批尺寸大小、正则化方法等。</p> <h2 id="偏差与方差"><strong>偏差与方差</strong></h2> <p>由高偏差带来的欠拟合和由高方差带来的过拟合。一般而言，解决高偏差的问题是选择更复杂的网络或不同的神经网络架构，而解决高方差的问题可以添加正则化、减少模型冗余或使用更多的数据进行训练。</p> <h3 id="正则化"><strong>正则化</strong></h3> <p>正则化是解决高方差或模型过拟合的主要手段，过去数年，研究者提出和开发了多种适合机器学习算法的正则化方法，如数据增强、L2 正则化（权重衰减）、L1 正则化、Dropout、Drop Connect、随机池化和提前终止等。</p></div> <div class="page-edit"><!----> <!----></div> <!----> </div> <!----></div></div>
    <script src="/assets/js/app.b74a338b.js" defer></script><script src="/assets/js/6.1e25e40e.js" defer></script>
  </body>
</html>
